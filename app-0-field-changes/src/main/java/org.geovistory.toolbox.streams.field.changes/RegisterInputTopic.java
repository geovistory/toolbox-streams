package org.geovistory.toolbox.streams.field.changes;

import dev.projects.info_proj_rel.Key;
import dev.projects.info_proj_rel.Value;
import org.apache.kafka.common.serialization.Serde;
import org.apache.kafka.common.utils.Bytes;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.kstream.*;
import org.apache.kafka.streams.state.KeyValueStore;
import org.eclipse.microprofile.config.inject.ConfigProperty;
import org.geovistory.toolbox.streams.lib.TopicNameEnum;

import javax.enterprise.context.ApplicationScoped;
import javax.inject.Inject;

/**
 * This class provides helper methods to register
 * source topics (topics consumed but not generated by this app)
 */
@ApplicationScoped
public class RegisterInputTopic {
    @Inject
    AvroSerdes avroSerdes;
    @Inject
    public BuilderSingleton builderSingleton;

    @ConfigProperty(name = "ts.input.topic.name.prefix", defaultValue = "")
    String prefix;

    RegisterInputTopic() {
    }

    public RegisterInputTopic(AvroSerdes avroSerdes, BuilderSingleton builderSingleton) {
        this.avroSerdes = avroSerdes;
        this.builderSingleton = builderSingleton;
    }

    public KTable<Key, Value> proInfoProjRelTable() {
        return getRepartitionedTable(
                prefixedIn(prefix, TopicNameEnum.pro_info_proj_rel.getValue()),
                avroSerdes.ProInfoProjRelKey(),
                avroSerdes.ProInfoProjRelValue()
        );
    }

    public KTable<dev.information.statement.Key, dev.information.statement.Value> infStatementTable() {
        return getRepartitionedTable(
                prefixedIn(prefix, TopicNameEnum.inf_statement.getValue()),
                avroSerdes.InfStatementKey(),
                avroSerdes.InfStatementValue()
        );
    }

    static private String prefixedIn(String prefix, String name) {
        return prefix + "." + name;
    }

    /**
     * Register a KStream and map it to a new KTable to ensure proper partitioning
     * This seems to be needed to correctly join topics created by debezium, since they have
     * a different Partitioner then this Kafka Streams application.
     *
     * @param topicName name of topic to consume from
     * @param kSerde    key Serde
     * @param vSerde    value Serde
     * @return KTable
     */
    protected <K, V> KTable<K, V> getRepartitionedTable(String topicName, Serde<K> kSerde, Serde<V> vSerde) {

        return getStream(topicName, kSerde, vSerde)
                .map(KeyValue::pair, Named.as(topicName + "-mark-for-repartition"))
                .toTable(
                        Named.as(topicName + "-to-table"),
                        Materialized
                                .<K, V, KeyValueStore<Bytes, byte[]>>as(topicName + "-store")
                                .withKeySerde(kSerde)
                                .withValueSerde(vSerde)
                );
    }


    protected <K, V> KStream<K, V> getStream(String topicName, Serde<K> kSerde, Serde<V> vSerde) {
        return builderSingleton.builder.stream(topicName, Consumed.with(kSerde, vSerde).withName(topicName + "-consumer"));
    }
}