# App settings
create.output.for.postgres=false
ts.input.topic.name.prefix=
ts.output.topic.name.prefix=
prefix=${ts.input.topic.name.prefix}
ts.output.topic.partitions=4
ts.output.topic.replication.factor=3

# Input topics
ts.topic.project.statement.with.literal=my-app.project.statement.with.literal
ts.topic.project.statement.with.entity=my-app.project.statement.with.entity
ts.topic.project.entity.label=my-app.project.entity.label
ts.topic.project.entity=my-app.project.entity
ts.topic.project.class.label=my-app.project.class.label
ts.topic.ontome.property.label=my-app.ontome.property.label
ts.topic.projects.project=my-app.projects.project

# Quarkus kafka streams settings
quarkus.kafka-streams.application-id=rdf
quarkus.kafka-streams.topics=\
  ${ts.topic.project.statement.with.literal},\
  ${ts.topic.project.statement.with.entity},\
  ${ts.topic.project.entity},\
  ${ts.topic.project.entity.label},\
  ${ts.topic.project.class.label},\
  ${ts.topic.ontome.property.label},\
  ${ts.topic.projects.project}

# kafka-streams pass-through options
## general
kafka-streams.bootstrap-servers=localhost:29092
kafka-streams.state.dir=kafka_streams_state
kafka-streams.topology.optimization=all
kafka-streams.processing.guarantee=exactly_once_v2

# streams
kafka-streams.cache.max.bytes.buffering=10240
kafka-streams.commit.interval.ms=100
kafka-streams.metadata.max.age.ms=500
kafka-streams.buffered.records.per.partition=1000

# producer
kafka-streams.producer.max.request.size=20971760
kafka-streams.producer.buffer.memory=33554432
kafka-streams.producer.send.buffer.bytes=131072
kafka-streams.producer.interceptor.classes=

#consumer
kafka-streams.consumer.isolation.level=read_committed
kafka-streams.consumer.fetch.max.bytes=52428800
kafka-streams.consumer.fetch.max.wait.ms=500
kafka-streams.consumer.receive.buffer.bytes=32768
kafka-streams.consumer.interceptor.classes=

# debug / metrics configs
kafka-streams.metrics.recording.level=INFO
%test.quarkus.log.category."io.confluent.kafka.serializers".level=WARN
management.metrics.tags.application=${quarkus.kafka-streams.application-id}

# Build settings
quarkus.native.container-build=true

# Docker settings
quarkus.container-image.group=geovistory
quarkus.container-image.registry=ghcr.io
quarkus.container-image.push=true

########## Dev Setup ########

# disable launching of apicurio-registry container in devservices (dev/test mode)
quarkus.apicurio-registry.devservices.enabled=false

# disable launching of kafka broker, since we set up redpanda ourselves
%dev.quarkus.kafka.devservices.enabled=false

# Dev mode
%dev.kafka.bootstrap.servers=localhost:1121,localhost:1122,localhost:1123
%dev.quarkus.kafka.streams.bootstrap.servers=${kafka.bootstrap.servers}
%dev.schema.registry.url=http://localhost:1127
%dev.quarkus.kafka.streams.schema.registry.url=${schema.registry.url}
%dev.kafka-streams.state.dir=state_dev_mode
%dev.ts.output.topic.name.prefix=ts_rdf
%dev.ts.topic.project.statement.with.literal=ts_entity_label_project_statement_with_literal
%dev.ts.topic.project.statement.with.entity=ts_entity_label_project_statement_with_entity
%dev.ts.topic.project.entity.label=ts_entity_label_project_entity_label
%dev.ts.topic.project.entity=ts_entity_label_project_entity
%dev.ts.topic.project.class.label=ts_base_config_project_class_label
%dev.ts.topic.ontome.property.label=ts_base_model_ontome_property_label
%dev.ts.topic.projects.project=dev.projects.project
