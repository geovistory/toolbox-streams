/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package org.geovistory.toolbox.streams.app;

import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.config.TopicConfig;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.geovistory.toolbox.streams.lib.AppConfig;

import java.util.Properties;

class App {
    public static void main(String[] args) {

        StreamsBuilder builder = new StreamsBuilder();
        var a = ProjectProfilesTopology.addProcessors(builder);
        var b = ProjectPropertyTopology.addProcessors(a.builder(), a.projectProfileStream());
        var topology = b.build();
        Properties props = getConfig();

        // create the output topics
        var admin = new Admin();
        admin.createTopic(ProjectProfilesTopology.output.TOPICS.project_profile);
        admin.createTopic(ProjectPropertyTopology.output.TOPICS.project_property);

        // create intermediate topic with large max. message
        admin.createTopic(
                AppConfig.INSTANCE.getApplicationId() + "-" + ProjectPropertyTopology.inner.TOPICS.profile_with_project_properties + "-changelog",
                20971760
        );

        // build the topology
        System.out.println("Starting Toolbox Streams App v" + BuildProperties.getDockerTagSuffix());

        // create the streams app
        //noinspection resource
        KafkaStreams streams = new KafkaStreams(topology, props);

        // close Kafka Streams when the JVM shuts down (e.g. SIGTERM)
        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));
        // start streaming!
        streams.start();
    }

    private static Properties getConfig() {

        AppConfig appConfig = AppConfig.INSTANCE;

        // set the required properties for running Kafka Streams
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, appConfig.getApplicationId());
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, appConfig.getKafkaBootstrapServers());
        props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG, StreamsConfig.OPTIMIZE);

        props.put(StreamsConfig.STATE_DIR_CONFIG, appConfig.getStateDir());

        props.put(StreamsConfig.topicPrefix(TopicConfig.CLEANUP_POLICY_CONFIG), TopicConfig.CLEANUP_POLICY_COMPACT);

        // See this for producer configs:
        // https://docs.confluent.io/platform/current/streams/developer-guide/config-streams.html#ak-consumers-producer-and-admin-client-configuration-parameters
        props.put(StreamsConfig.producerPrefix(ProducerConfig.MAX_REQUEST_SIZE_CONFIG), "20971760");
        /*

        props.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, AvroSerde.class);
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, AvroSerde.class);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        // URL for Apicurio Registry connection (including basic auth parameters)
        props.put(SerdeConfig.REGISTRY_URL, appConfig.getApicurioRegistryUrl());
        // Specify using specific (generated) Avro schema classes
        props.put(AvroKafkaSerdeConfig.USE_SPECIFIC_AVRO_READER, "true");
        props.put(SerdeConfig.AUTO_REGISTER_ARTIFACT, true);*/
        return props;
    }
}
