# App settings
create.output.for.postgres=false
ts.input.topic.name.prefix=
ts.output.topic.name.prefix=
prefix=${ts.input.topic.name.prefix}
ts.output.topic.partitions=4
ts.output.topic.replication.factor=3

# Input topics
ts.topic.ontome.property=ontome_property
ts.topic.ontome.class=ontome_class
ts.topic.ontome.property.label=ontome_property_label
ts.topic.ontome.class.label=ontome_class_label

# Quarkus kafka streams settings
quarkus.kafka-streams.application-id=my-app
quarkus.kafka-streams.bootstrap-servers=localhost:29092
quarkus.kafka-streams.topics=${ts.topic.ontome.property},\
  ${ts.topic.ontome.class},\
  ${ts.topic.ontome.property.label},\
  ${ts.topic.ontome.class.label},\
  ${prefix}.projects.project,\
  ${prefix}.projects.text_property,\
  ${prefix}.projects.entity_label_config,\
  ${prefix}.projects.dfh_profile_proj_rel,\
  ${prefix}.system.config

# kafka-streams pass-through options
## general
kafka-streams.state.dir=kafka_streams_state
kafka-streams.topology.optimization=all
kafka-streams.processing.guarantee=exactly_once_v2

# streams
kafka-streams.cache.max.bytes.buffering=10240
kafka-streams.commit.interval.ms=100
kafka-streams.metadata.max.age.ms=500
kafka-streams.buffered.records.per.partition=1000

# producer
kafka-streams.producer.max.request.size=20971760
kafka-streams.producer.buffer.memory=33554432
kafka-streams.producer.send.buffer.bytes=131072
kafka-streams.producer.interceptor.classes=

#consumer
kafka-streams.consumer.isolation.level=read_committed
kafka-streams.consumer.fetch.max.bytes=52428800
kafka-streams.consumer.fetch.max.wait.ms=500
kafka-streams.consumer.receive.buffer.bytes=32768
kafka-streams.consumer.interceptor.classes=

# debug / metrics configs
kafka-streams.metrics.recording.level=INFO
management.metrics.tags.application=${quarkus.kafka-streams.application-id}

# Build settings
quarkus.native.container-build=true

# Docker settings
quarkus.container-image.group=geovistory
quarkus.container-image.registry=ghcr.io
quarkus.container-image.push=true
