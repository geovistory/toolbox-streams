# App settings
ts.input.topic.name.prefix=
ts.output.topic.name.prefix=
prefix=${ts.input.topic.name.prefix}
ts.output.topic.partitions=4
ts.output.topic.replication.factor=3

# Quarkus kafka streams settings
quarkus.kafka-streams.application-id=my-app
quarkus.kafka-streams.bootstrap-servers=localhost:29092
quarkus.kafka-streams.topics=${prefix}.data_for_history.api_property,${prefix}.data_for_history.api_class


# kafka-streams pass-through options
## general
kafka-streams.state.dir=kafka_streams_state
kafka-streams.topology.optimization=all
kafka-streams.processing.guarantee=exactly_once_v2

# streams
kafka-streams.cache.max.bytes.buffering=10485760
kafka-streams.commit.interval.ms=100
kafka-streams.metadata.max.age.ms=500
kafka-streams.buffered.records.per.partition=1000

# producer
kafka-streams.producer.max.request.size=20971760
kafka-streams.producer.buffer.memory=33554432
kafka-streams.producer.send.buffer.bytes=131072
kafka-streams.producer.interceptor.classes=

#consumer
kafka-streams.consumer.isolation.level=read_committed
kafka-streams.consumer.fetch.max.bytes=52428800
kafka-streams.consumer.fetch.max.wait.ms=500
kafka-streams.consumer.receive.buffer.bytes=32768
kafka-streams.consumer.interceptor.classes=

# debug / metrics configs
kafka-streams.metrics.recording.level=INFO
management.metrics.tags.application=${quarkus.kafka-streams.application-id}

# Build settings
quarkus.native.container-build=true

# Docker settings
quarkus.container-image.group=geovistory
quarkus.container-image.registry=ghcr.io
quarkus.container-image.push=true
